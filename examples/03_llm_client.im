// LLM Client - Tools for calling LLM APIs

@tool(description: "Count tokens in text (approximate)")
fn count_tokens(text) {
    // Rough approximation: ~4 chars per token
    return len(text) / 4
}

@tool(description: "Build a chat message")
fn chat_message(role, content) {
    return {"role": role, "content": content}
}

@tool(description: "Build a chat completion request")
fn chat_request(messages, model) {
    return {
        "model": model,
        "messages": messages,
        "max_tokens": 500,
        "temperature": 0.7
    }
}

// Demo
print("=== LLM Client Tools ===")
print("")

let prompt = "Explain quantum computing in one sentence."
print("Prompt: " + prompt)
print("Estimated tokens: " + str(count_tokens(prompt)))

print("")
let messages = [
    chat_message("system", "You are a helpful assistant."),
    chat_message("user", "Hello!")
]

let request = chat_request(messages, "gpt-4")
print("Request body:")
print(json.encode(request))
